debug_info:
  bucket:
    type: "FILESYSTEM"
    config:
      directory: "./tmp"
  cache:
    type: "FILESYSTEM"
    config:
      directory: "./tmp"

scrape_configs:
  - job_name: "default"
    scrape_interval: "3s"
    static_configs:
      - targets: ["127.0.0.1:7070", "127.0.0.1:6000", "127.0.0.1:8080"]
        labels:
          service: "defaultservice"

  - job_name: "node"
    scrape_interval: "10s"
    scrape_timeout: "5s"
    static_configs:
      - targets: ["127.0.0.1:7070", "127.0.0.1:6000"]
        labels:
          service: "nodeservice"

  - job_name: "go"
    scrape_interval: "20s"
    scrape_timeout: "5s"
    static_configs:
      - targets: ["127.0.0.1:7070", "127.0.0.1:8080"]
        labels:
          service: "goservice"

  - job_name: "go2"
    scrape_interval: "20s"
    scrape_timeout: "5s"
    static_configs:
      - targets: ["127.0.0.1:7070", "127.0.0.1:8080"]
        labels:
          service: "goservice2"
  
  - job_name: "go3"
    scrape_interval: "20s"
    scrape_timeout: "5s"
    static_configs:
      - targets: ["127.0.0.1:7070", "127.0.0.1:8080"]
        labels:
          service: "goservice3"

  - job_name: "go4"
    scrape_interval: "20s"
    scrape_timeout: "5s"
    static_configs:
      - targets: ["127.0.0.1:7070", "127.0.0.1:8080"]
        labels:
          service: "goservice4"
  
  - job_name: "go5"
    scrape_interval: "20s"
    scrape_timeout: "5s"
    static_configs:
      - targets: ["127.0.0.1:7070", "127.0.0.1:8080"]
        labels:
          service: "goservice5"

  - job_name: "go6"
    scrape_interval: "20s"
    scrape_timeout: "5s"
    static_configs:
      - targets: ["127.0.0.1:7070", "127.0.0.1:8080"]
        labels:
          service: "goservice6"

  - job_name: "go7"
    scrape_interval: "20s"
    scrape_timeout: "5s"
    static_configs:
      - targets: ["127.0.0.1:7070", "127.0.0.1:8080"]
        labels:
          service: "goservice7"

    # Custom scrape endpoints can be added like just like the example below.
    # The profile name will be `fgprof`, and it will be scraped from the given
    # path and since it is a delta profile, a query parameter
    # ?seconds=<scrape-interval> will be added.
    #
    # profiling_config:
    #   pprof_config:
    #     fgprof:
    #       enabled: true
    #       path: /debug/pprof/fgprof
    #       delta: true
